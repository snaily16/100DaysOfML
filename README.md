# 100DaysOfML
I accept the challenge of Siraj Raval of 100 days of ML. I will learn and code machine learning for at least 1 hour everyday.

Day 1 : Stock Price Predictor <br />
Day 2 : Twitter Sentiment Analysis and Udacity Intro to Machine Learning - Lesson 11 Text Learning <br />
Day 3 : Created labelled CSV dataset of twitter tweets and its sentiments and trained a neural network model to classify images of clothing, like sneakers and shirts. <br />
Day 4 : Learned Bayes Theorem and Naive Bayes Classification Algorithm. Wrote a small program using sklearn to demonstrate Gaussian Naive Bayes. <br />
Day 5 : Built a Naive Bayes Classifier from Scratch using python and numpy package. Reference: https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/ <br/>
Day 6 : Learned Decision Tree Classifier and implemented it using sklearn on iris dataset. Started learning Pandas library. <br />
Day 7 : Visualizing Data from Data Science from Scratch : First Principles with Python. <br />
Day 8 : Learnt Pandas from Kaggle - 
	1.Creating, reading and writing workbook, 
	2.Indexing, Selecting & Assigning, 
	3. Summary functions and maps workbook <br />
Day 9 : 4. Grouping and Sorting
		5. Datatypes and missing data workbook
		6. Renaming and combining workbook
		7. Method chaining workbook
Day 10 : Movie Recommendation using LightFM dependency and movielens dataset<br />
Day 11 : Done some coding in Python for All Women Hackthon - Hacckerrank<br />
Day 12 : Studied Feature Selection <br />
Day 13 : Built a spam filter using Naive Bayes classifier and enron dataset<br />
Day 14 : Working on building Spam classifier from scratch using Pandas and Numpy library<br />
Day 15 : Predicted house prices using Linear Regression.<br />
Day 16 : Visualization with Seaborn<br />
Day 17 : Built a single layer neural network using Python Numpy. <br />
Day 18 : Built decision tree from scratch using Python. <br />
Day 19 : Built KNN classifier from scratch <br />
Day 20 : Chapter 1 of Data Science from Scratch : Motivating Hypothetical - DataSciencester<br />
Day 21 : Chapter 4 : Linear Algebra and Chapter 5: Statistics (Revised some mathemathical concepts). <br />
Day 22 : Completed Quiz project task of Feature Selection and started new concept - PCA - Principal Component Analysis in Udacity Into to ML<br />
Day 23 : Completed PCA and Validation lessons  <br/>
Day 24 : Completed Evaluation Metric lesson <br/>
Day 25, 26, 27: Completed project on Enron dataset<br />
Day 28 : Implemented simple linear regression from scratch. <br/>
Day 29 : Studied gradient descent. <br />
Day 30 : Watched Andrew Ng videos on multiple linear regression and implemented it. <br />
Day 31 : Studied Logistic Regression<br/>
Day 32, 33 : Built Binary Classification Logistic Regression from scratch using python <br/>
Day 34, 35 : Learned Tensorflow basics<br />
Day 36, 37, 38: Working on Kaggle's Titanic: Machine Learning from Disaster
Day 39, 40: Watched youtube videos of Siraj and read medium posts.<br/>
Day 41, 42: Started Statistic course of Udacity.<br/>
Day 43 : Learned from Coursera CNN course - Edge Detection, Padding, Strided cnn, pooling.<br/>
Day 44 : Implemnted linear regression using Tensorflow<br/>
Day 45 : Working on MNIST digit recognizer.<br/>
Day 46 : Started learning Angular and Node.js side by side.<br/>
Day 47 : Predicting Boston Housing Prices using Tensorflow.<br/>
Day 48 : Completed 7 lessons of Udacity Intro to Statistics<br/>
Day 49 : Completed Kaggle's Digit Recognizer.<br/>
Day 50 : Learned basics of CNN and wrote edge detection code.<br/>
Day 51 : Learned classic neural network architectures - LeNet, AlexNet, VGG-16, ResNet.<br/>
Day 52 : Used Google Collab, learned to load Kaggle's dataset in it. Also learnt its basic functionality<br/>
Day 53 : Working on Cats vs Dogs with ConvNet using Keras<br/>
Day 54 : Created conv model similar to VGG-16 in Keras to classify between a dog and cat, also learned data augmentation<br/>
Day 55 : Published my first story on Medium regarding Google Colab<br/>
Day 56 : Completed the Cat vs Dog classification. Although achieved just 70% accuracy, studying related to overfitting problems, and use of optimizers and callbacks. Will try to achieve better accuracy.<br/>
Day 57 : Wrote my 2nd @Medium story - on how to import data to google colab.<br/>
Day 58 : Read and watched videos on Transfer learning<br/>
Day 59 : Wrote ML code using Logistic Regression to predict whether a patient has diabetes or not. <br/>
Day 60 : Started learning Flask.<br/>
Day 61 : Created my first webapp using Flask to predict diabetes. Still work in progress, will try to make it look little classy.<br/>
Day 62 & 63 : Did nothing related to ML, but taught JAVA programming to one of my relativeðŸ™‚<br/>
Day 64 : Watched @sirajraval 's video of How to Generate Art and How to Do Style Transfer with Tensorflow. Now reading a research paper - Neural Algorithm of Artistic Style<br/>
Day 65 : Wrote a program to generate art.<br/>
Day 66 : Worked on YOLO object detection using darkflow. <br/>
Day 67 : Built Sentiment Analyser using Tflearn - A step towards NLP.<br/>
Day 68 : Studied statistics<br/>
Day 69 : Wrote a code to detect faces with OpenCV and Deep learning. Reference @PyImageSearch tutorials<br/>
Day 70 : Revised basics of OpenCV - array slicing, resizing, rotating, smoothing, drawing on image, etc<br/>
