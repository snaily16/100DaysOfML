{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spam filtering\n",
    "import nltk\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data\n",
    "\n",
    "def load_data(folder):\n",
    "    a_list = []\n",
    "    file_list = os.listdir(folder)\n",
    "    for a_file in file_list:\n",
    "        f_name = folder+a_file #.encode('utf-8').strip()\n",
    "        f = open(f_name, 'rb')\n",
    "        a_list.append(f.read())\n",
    "    f.close()\n",
    "    return a_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam = load_data('enron1/spam/')\n",
    "ham = load_data('enron1/ham/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_emails = [(email, 'spam') for email in spam]\n",
    "ham_emails = [(email, 'ham') for email in ham]\n",
    "all_emails = spam_emails + ham_emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5172\n"
     ]
    }
   ],
   "source": [
    "print(len(all_emails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle\n",
    "import random\n",
    "\n",
    "random.shuffle(all_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the data\n",
    "from nltk import word_tokenize, WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sentence):\n",
    "    tokens = word_tokenize(sentence)\n",
    "    return[lemmatizer.lemmatize(word.lower()) for word in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'there', ',', 'hello', 'world', '!']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess('Hi there, Hello world!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the features\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stoplist = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag of words\n",
    "from collections import Counter\n",
    "\n",
    "def get_features(text, setting):\n",
    "    if setting == 'bow':\n",
    "        return {word: count for word, count in Counter(preprocess(text)).items() if not word in stoplist}\n",
    "    else:\n",
    "        return {word: True for word in preprocess(text) if not word in stoplist}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"b'subject\": 1,\n",
       " ':': 1,\n",
       " 'new': 1,\n",
       " 'pan': 1,\n",
       " 'energy': 1,\n",
       " 'exchange': 1,\n",
       " 'deal': 2,\n",
       " 'meeting\\\\r\\\\ndaren': 1,\n",
       " ',': 4,\n",
       " '\\\\r\\\\nplease': 1,\n",
       " 'let': 1,\n",
       " 'know': 1,\n",
       " 'time': 1,\n",
       " 'meet': 1,\n",
       " 'megan': 1,\n",
       " 'new\\\\r\\\\nexchange': 1,\n",
       " '.\\\\r\\\\nprior': 1,\n",
       " 'settling': 1,\n",
       " 'feb': 1,\n",
       " '.': 1,\n",
       " '2000': 1,\n",
       " 'production': 1,\n",
       " 'issue': 1,\n",
       " 'need': 1,\n",
       " 'to\\\\r\\\\nhave': 1,\n",
       " 'clarified': 1,\n",
       " 'sale': 1,\n",
       " 'supply': 1,\n",
       " 'side': 1,\n",
       " '\\\\r\\\\nthanks': 1,\n",
       " '\\\\r\\\\nkatherine\\\\r\\\\n5': 1,\n",
       " '-': 1,\n",
       " '8643': 1,\n",
       " \"'\": 1}"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = [(email, label )for (email, label) in all_emails]\n",
    "get_features(str(f[0][0]),'bow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [(get_features(str(email),''), label) for (email,label) in all_emails]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = [(get_features(str(email),'bow'), label) for (email,label) in all_emails]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train and test sets\n",
    "from nltk import NaiveBayesClassifier, classify\n",
    "\n",
    "def train(features, sample_proportion):\n",
    "    train_size = int(len(features) * sample_proportion)\n",
    "    train_set, test_set = features[:train_size], features[train_size:]\n",
    "    print('Training set: ',str(len(train_set)))\n",
    "    print('Test set: ',str(len(test_set)))\n",
    "    \n",
    "    #train\n",
    "    classifier = NaiveBayesClassifier.train(train_set)\n",
    "    return train_set, test_set, classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:  4137\n",
      "Test set:  1035\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set, classifier = train(all_features, 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#evaluate your classifier performance\n",
    "def evaluate(train_set, test_set, classifier):\n",
    "    print('Accuracy of training set :', str(classify.accuracy(classifier, train_set)))\n",
    "    print('Accuracy of test set :', str(classify.accuracy(classifier, test_set)))\n",
    "    print(classifier.show_most_informative_features(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training set : 0.9724437998549673\n",
      "Accuracy of test set : 0.9468599033816425\n",
      "Most Informative Features\n",
      "            prescription = 1                spam : ham    =    113.8 : 1.0\n",
      "                    2004 = 1                spam : ham    =     89.5 : 1.0\n",
      "                      xl = 2                 ham : spam   =     83.6 : 1.0\n",
      "              compliance = 1                spam : ham    =     83.2 : 1.0\n",
      "                    pain = 1                spam : ham    =     71.8 : 1.0\n",
      "                pm\\r\\nto = 1                 ham : spam   =     70.7 : 1.0\n",
      "                  dealer = 1                spam : ham    =     70.3 : 1.0\n",
      "                     sex = 1                spam : ham    =     63.8 : 1.0\n",
      "                featured = 1                spam : ham    =     59.0 : 1.0\n",
      "              nomination = 1                 ham : spam   =     58.8 : 1.0\n",
      "                     gas = 2                 ham : spam   =     57.6 : 1.0\n",
      "                   cheap = 1                spam : ham    =     57.3 : 1.0\n",
      "                mail\\r\\n = 1                spam : ham    =     54.1 : 1.0\n",
      "             legislation = 1                spam : ham    =     54.1 : 1.0\n",
      "               clearance = 1                spam : ham    =     52.5 : 1.0\n",
      "                     gas = 1                 ham : spam   =     46.6 : 1.0\n",
      "                deciding = 1                spam : ham    =     46.0 : 1.0\n",
      "                    huge = 1                spam : ham    =     46.0 : 1.0\n",
      "            solicitation = 1                spam : ham    =     41.2 : 1.0\n",
      "               .\\r\\nbest = 1                spam : ham    =     41.2 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "evaluate(train_set, test_set, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
